Driver
======

Now that you've successfully written your kernel, how do you execute it?
That's the job of the driver.

The driver (`dcompute.driver`) manages the interactions with the compute APIs
(OpenCL and CUDA). This doesn't stop you interacting with them directly, it
just provides you with a consistent and (as much as is possible) a boiler-plate 
free interface.

API objects
-----------

There are a number of driver API objects that wrap the underlying compute API 
objects. They are summarised briefly below. More in depth information is available
in the corresponding subsection of this chapter.

**Platform:** Represents one implementation of a compute API. You can query object for the
devices that are available though it.

**Device:** Represents a unit of execution (e.g. a GPU). Group devices together to form a
context. You can query a large number of properties about performance characteristics
and available memory.

**Context:** A key API object. You create queues, buffers/images, samplers and programs from it.

**Memory:** Represents a region of memory. An abstract base class of buffers & images.

**Buffers:** Represents a 1,2 or 3D (possibly strided) linear view of memory.

**Images:**  Represents a 1,2 or 3D view of memory whose layout is determined by the format of the
image (number and datatype of the channels).

**Programs:** Represents a hunk of code for a context. You can create Kernels from a linked 
program (i.e. all external dependencies resolved).

**Queue:** Represents a list of work (data transfers & kernel launches) and the graph of their
dependencies.

**Kernel:** Represents a callable function from a Program and associated function parameters.
Submit kernels with supplied parameters to a queue to execute them on the queue's 
context's devices.

**Event:** Represents a future return value from executing an asynchronous operation, such 
as a data transfer or kernel launch.

# Running a Kernel

Now, let's run our `mykernel` kernel that we have built up (see `04-std/01-index.md`). Recall
that our kernel code should be in a separate file. For our main function, we can have something
as shown below. This is assumes compilation for CUDA backend. Note that we import our 
`mykernels` module containing our kernel code and the dcompute driver for cuda.

```d
import std.stdio;
import ldc.dcompute;
import std.algorithm;
import std.stdio;
import std.file;
import std.traits;
import std.meta;
import std.exception : enforce;
import std.experimental.allocator;
import std.array;
import mykernels;
import dcompute.driver.cuda;

int main()
{
    enum size_t N = 128;
    float c = 5.0;
    float[N] res, x;
    foreach (i; 0 .. N)
    {
        x[i] = i;
    }

    Platform.initialise();

    auto devs = Platform.getDevices(theAllocator);
    auto dev   = devs[0];
    auto ctx   = Context(dev); scope(exit) ctx.detach();

    // Change the file to match your GPU.
    Program.globalProgram = Program.fromFile("kernels_cuda800_64.ptx");
    auto q = Queue(false);

    Buffer!(float) b_res, b_x;
    b_res =  Buffer!(float)(res[]); scope(exit) b_res.release();
    b_x   =  Buffer!(float)(x[]);   scope(exit) b_x.release();

    b_x.copy!(Copy.hostToDevice);

    q.enqueue!(mykernel)
              ([N,1,1],[1,1,1])
              (b_res,b_x,c);
    b_res.copy!(Copy.deviceToHost);

    foreach(i; 0 .. N)
        enforce(res[i] == x[i] + c);
    writeln(res[]);

    return 0;
}
```
It is important to change the file path on the `Program.fromFile("kernels_cuda800_64.ptx")` line
to the ptx file generated by the compilation step. Depending on how you set up dub, it may be in
`./.dub/obj` or just your project directory. You should verify that your kernels actually show
up in the ptx file after running dub build (it's in plaintext).

With the above example, we should get a successful run with the integers from 5 to 132 printed, since
our kernel adds c, which is 5 in this case, to the input vector, which has 0 to 127 in our case.

See `source/dcompute/tests` for examples of a slightly more complicated kernel and running with opencl driver.
